{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRS.from_epsg(4326)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "fp = \"datasets/DIM_SPOT7_PMS_202301220703517_ORT_AKWOI-00056166/PROD_SPOT7_001/VOL_SPOT7_001_A/IMG_SPOT7_PMS_001_A/IMG_SPOT7_PMS_202301220703517_ORT_AKWOI-00056166_R2C2.TIF\"\n",
    "img = rasterio.open(fp)\n",
    "img.crs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "newarr = img.read()//16\n",
    "\n",
    "newarr.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5405, 7353)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newarr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 2048, 2048)\n",
      "(0, 1536, 2048, 3584)\n",
      "(0, 3072, 2048, 5120)\n",
      "(0, 4608, 2048, 6656)\n",
      "(0, 6144, 2048, 8192)\n",
      "(1536, 0, 3584, 2048)\n",
      "(1536, 1536, 3584, 3584)\n",
      "(1536, 3072, 3584, 5120)\n",
      "(1536, 4608, 3584, 6656)\n",
      "(1536, 6144, 3584, 8192)\n",
      "(3072, 0, 5120, 2048)\n",
      "(3072, 1536, 5120, 3584)\n",
      "(3072, 3072, 5120, 5120)\n",
      "(3072, 4608, 5120, 6656)\n",
      "(3072, 6144, 5120, 8192)\n",
      "(4608, 0, 6656, 2048)\n",
      "(4608, 1536, 6656, 3584)\n",
      "(4608, 3072, 6656, 5120)\n",
      "(4608, 4608, 6656, 6656)\n",
      "(4608, 6144, 6656, 8192)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "def split_image(img, window_size, overlap):\n",
    "    height, width = img.shape[1:]\n",
    "    img= np.swapaxes(img, 0, 2)\n",
    "    img = Image.fromarray(img.astype(np.uint8))\n",
    "    x_step = window_size - overlap\n",
    "    y_step = window_size - overlap\n",
    "    for y in range(0, height, y_step):\n",
    "        for x in range(0, width, x_step):\n",
    "            #image = img[y:y+window_size, x:x+window_size, :]\n",
    "            box = (y,  x, y+window_size, x+window_size)\n",
    "            print(box)\n",
    "            img.crop(box).save(f\"datasets/new_images/real_image_2023_22_{x}_{y}.jpg\")\n",
    "            #Image.fromarray(image.astype(np.uint8)).save(f\"datasets/new_images/real_image_2020_12_{x}_{y}.jpg\")\n",
    "            \n",
    "\n",
    "\n",
    "#47.91\n",
    "\n",
    "window_size = 2048\n",
    "overlap = 512\n",
    "split_image(newarr[:3], window_size, overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "# Load image\n",
    "img = Image.open(\"datasets/synthetic_images/no_label/empty_sea_23.jpg\")\n",
    "\n",
    "# Output directory for the smaller images\n",
    "output_dir = 'datasets/synthetic_images/no_label/'\n",
    "\n",
    "# Parameters for cropping\n",
    "crop_size = 680\n",
    "overlap = 120\n",
    "\n",
    "# Calculate the number of crops in the x and y directions\n",
    "num_crops_x = (img.width - crop_size) // (crop_size - overlap) + 1\n",
    "num_crops_y = (img.height - crop_size) // (crop_size - overlap) + 1\n",
    "\n",
    "# Loop over each crop\n",
    "for i in range(num_crops_x):\n",
    "    for j in range(num_crops_y):\n",
    "        # Calculate the coordinates for cropping the image\n",
    "        left = i * (crop_size - overlap)\n",
    "        top = j * (crop_size - overlap)\n",
    "        right = left + crop_size\n",
    "        bottom = top + crop_size\n",
    "\n",
    "        # Crop the image\n",
    "        cropped_img = img.crop((left, top, right, bottom))\n",
    "\n",
    "        # Save the cropped image with a random name\n",
    "        image_name = os.path.join(output_dir, f'S_23_E_{i}_{j}.png')\n",
    "        cropped_img.save(image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "label = np.ones([680, 680, 3], dtype=int)\n",
    "\n",
    "img= Image.fromarray(label.astype(np.uint8))\n",
    "output_dir = 'datasets/synthetic_images/total/'\n",
    "for i in os.listdir(output_dir):\n",
    "    image_name = output_dir + i.replace(\"S\", \"L\")\n",
    "    img.save(image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "# Load image\n",
    "img = Image.open(\"datasets/synthetic_images/platforms/empty_sea_pt_20.jpg\")\n",
    "lab_pt = Image.open(\"datasets/synthetic_images/task-60-annotation-101-by-2-tag-platform-0.png\")\n",
    "\n",
    "nppt = np.asarray(lab_pt)\n",
    "print(nppt)\n",
    "newpt= np.zeros_like([nppt, nppt, nppt])\n",
    "newpt[1] = nppt\n",
    "print(newpt)\n",
    "newpt= np.swapaxes(newpt, 0, 1)\n",
    "newpt= np.swapaxes(newpt, 1, 2)\n",
    "\n",
    "\n",
    "lab_pt = Image.fromarray(newpt.astype(np.uint8))\n",
    "\n",
    "\n",
    "# Output directory for the smaller images\n",
    "output_dir = 'datasets/synthetic_images/total/'\n",
    "\n",
    "# Parameters for cropping\n",
    "crop_size = 680\n",
    "overlap = 400\n",
    "\n",
    "# Calculate the number of crops in the x and y directions\n",
    "num_crops_x = (img.width - crop_size) // (crop_size - overlap) + 1\n",
    "num_crops_y = (img.height - crop_size) // (crop_size - overlap) + 1\n",
    "\n",
    "# Loop over each crop\n",
    "for i in range(num_crops_x):\n",
    "    for j in range(num_crops_y):\n",
    "        # Calculate the coordinates for cropping the image\n",
    "        left = i * (crop_size - overlap)\n",
    "        top = j * (crop_size - overlap)\n",
    "        right = left + crop_size\n",
    "        bottom = top + crop_size\n",
    "\n",
    "        # Crop the image\n",
    "        cropped_img = img.crop((left, top, right, bottom))\n",
    "        cropped_lab = lab_pt.crop((left, top, right, bottom))\n",
    "\n",
    "        # Save the cropped image with a random name\n",
    "        image_name = os.path.join(output_dir, f'S_20_PT_{i}_{j}.png')\n",
    "        lab_name = os.path.join(output_dir, f'N_20_PT_{i}_{j}.png')\n",
    "        cropped_img.save(image_name)\n",
    "        cropped_lab.save(lab_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "# Load image\n",
    "img = Image.open(\"datasets/synthetic_images/oil_platforms/empty_sea_pt_woil_20.jpg\")\n",
    "lab_pt = Image.open(\"datasets/synthetic_images/task-60-annotation-101-by-2-tag-platform-0.png\")\n",
    "lab_leak = Image.open(\"datasets/synthetic_images/task-60-annotation-101-by-2-tag-leak-0.png\")\n",
    "\n",
    "\n",
    "nppt = np.asarray(lab_pt)\n",
    "npleak = np.asarray(lab_leak)\n",
    "newpt= np.zeros_like([nppt, nppt, nppt])\n",
    "\n",
    "newpt[1] = nppt\n",
    "newpt[2] = npleak\n",
    "\n",
    "newpt= np.swapaxes(newpt, 0, 1)\n",
    "newpt= np.swapaxes(newpt, 1, 2)\n",
    "\n",
    "\n",
    "lab_pt = Image.fromarray(newpt.astype(np.uint8))\n",
    "\n",
    "\n",
    "# Output directory for the smaller images\n",
    "output_dir = 'datasets/synthetic_images/total/'\n",
    "\n",
    "# Parameters for cropping\n",
    "crop_size = 680\n",
    "overlap = 340\n",
    "\n",
    "# Calculate the number of crops in the x and y directions\n",
    "num_crops_x = (img.width - crop_size) // (crop_size - overlap) + 1\n",
    "num_crops_y = (img.height - crop_size) // (crop_size - overlap) + 1\n",
    "\n",
    "# Loop over each crop\n",
    "for i in range(num_crops_x):\n",
    "    for j in range(num_crops_y):\n",
    "        # Calculate the coordinates for cropping the image\n",
    "        left = i * (crop_size - overlap)\n",
    "        top = j * (crop_size - overlap)\n",
    "        right = left + crop_size\n",
    "        bottom = top + crop_size\n",
    "\n",
    "        # Crop the image\n",
    "        cropped_img = img.crop((left, top, right, bottom))\n",
    "        cropped_lab = lab_pt.crop((left, top, right, bottom))\n",
    "\n",
    "        # Save the cropped image with a random name\n",
    "        image_name = os.path.join(output_dir, f'S_20_WLPT_{i}_{j}.png')\n",
    "        lab_name = os.path.join(output_dir, f'L_20_WLPT_{i}_{j}.png')\n",
    "        cropped_img.save(image_name)\n",
    "        cropped_lab.save(lab_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_images_path = \"datasets/real_images/\"\n",
    "synthetic_csv_path = \"datasets/real_images/label_txt.txt\"\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "with open(synthetic_csv_path, 'w') as f:\n",
    "    for i in os.listdir(synthetic_images_path):\n",
    "        f.write(f\"{i}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/mirakram/Projects/oil_spill/datasets/dataset_retrieval.py\", line 7, in <module>\n",
      "    import constants\n",
      "ModuleNotFoundError: No module named 'constants'\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oilspill",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1e3e629e7eb1aff7ce1dd372ec51ff80f2baecd128fa7f984f0d5686ee22c37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
